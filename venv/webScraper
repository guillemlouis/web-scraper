import requests
import urllib3.request
import urllib
import os

from bs4 import BeautifulSoup

# access to the website with the url
url = 'https://dumps.wikimedia.org/other/pagecounts-raw/2008/2008-01/'
response = requests.get(url)

# beautiful soup parses the HTML
html = BeautifulSoup(response.text, "html.parser")

# iterate through the links
for a in html.findAll('a', href=True):
    # builds the url to download from
    download_URL = url + str(a['href'])

    # builds the path on the system to which you want to download
    # os.path.expanduser will make this work in every system (gets the path to the home directory)
    destination_path = os.path.expanduser('~/Downloads') + str(a['href'])

    # download the file, from the download url to destination download path
    urllib.urlretrieve(download_URL,destination_path)
